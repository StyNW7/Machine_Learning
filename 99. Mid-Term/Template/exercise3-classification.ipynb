{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc56ffb",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bed153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import r2_score, f1_score, roc_auc_score, accuracy_score, recall_score, precision_score, confusion_matrix, classification_report, mean_squared_error, root_mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bee315",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77786589",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Data/Breast_Cancer_Classification.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56707a50",
   "metadata": {},
   "source": [
    "# Simple Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceadeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"id\", \"Unnamed: 32\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63572de9",
   "metadata": {},
   "source": [
    "#### Drop 2 kolom yang tidak penting sama sekali yaitu hanya sebuah ID dan Unnamed Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e8517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = data.pop(\"diagnosis\")\n",
    "data[\"diagnosis\"] = data_out\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d98cbc",
   "metadata": {},
   "source": [
    "#### Pindahin data Label / Target ke paling akhir / ujung biar memudahkan untuk melakukan iterasi for each nantinya ataupun ketika ingin memisahkan data x dan y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d2a92",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d10e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f11f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca5ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e86b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a989dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c282a59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5264c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns[:-1]:\n",
    "    if (data[column].dtype != \"object\"):\n",
    "        sns.histplot(data=data, x=column)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cd41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns[:-1]:\n",
    "    if (data[column].dtype != \"object\"):\n",
    "        sns.boxplot(data=data, x=column)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f2bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns[:-1]:\n",
    "    if (data[column].dtype != \"object\"):\n",
    "        sns.scatterplot(data=data, x=column, y=\"diagnosis\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18acb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns[:-1]:\n",
    "    if (data[column].dtype != \"object\"):\n",
    "        print (f\"{column}: Skewness: {data[column].skew()}, Kurtosis: {data[column].kurt()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4bb0f8",
   "metadata": {},
   "source": [
    "#### Hasil EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f8c36d",
   "metadata": {},
   "source": [
    "1. Hampir semua fitur yang ada berdistribusi tidak normal karena hasil nilai skewness dan gambar menunjukkan bahwa mereka cenderung mengarah ke \"Right Skewed\"\n",
    "\n",
    "2. Nilai kurtosis yang mengukur seberapa tinggi dan lebar ekor distribusi memberi gambaran kepekatan data di sekitar mean dan seberapa jauh data menyebar hingga ke ekor. Dengan nilai kurtosis yang acak tersebut artinya ada data yang menyebar rata, tapi ada juga nilai kurtosis tinggi artinya terdapat outliers.\n",
    "\n",
    "- Nilai Skewness yang bagus -> Mendekati 0 artinya Distribusi Normal\n",
    "\n",
    "- Nilai Kurtosis yang bagus -> Mendekati 3 artinya distribusi normal\n",
    "\n",
    "Hal ini menyebabkan beberapa hal\n",
    "- Fill NA dari data numeric akan menggunakan Median -> Karena data tidak berdistribusi secara normal, jadi lebih baik menggunakan nilai Median dibandingkan Mean (rata-rata)\n",
    "- Fill NA dari data object akan menggunakan Modus (mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead4ad8",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3114f8b",
   "metadata": {},
   "source": [
    "#### Anggep aja ada NA yaa, jadi aku lanjutin preprocessing-nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f8ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e66db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data.isna().sum() / len(data)\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da7d25c",
   "metadata": {},
   "source": [
    "### Drop NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f679002",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in missing_values.items():\n",
    "    if (value > 0.5):\n",
    "        data = data.drop(columns=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f03d3d",
   "metadata": {},
   "source": [
    "### Fill NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b24ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data.columns:\n",
    "    if (data[column].isna().any()):\n",
    "        if (data[column].dtype == \"object\"):\n",
    "            data[column] = data[column].fillna(data[column].mode()[0])\n",
    "        else:\n",
    "            data[column] = data[column].fillna(data[column].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ff380",
   "metadata": {},
   "source": [
    "### Encoding (Categorical -> Numerical Data Types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoded = {}\n",
    "\n",
    "for column in data.columns:\n",
    "    if (data[column].dtype == \"object\"):\n",
    "        data[column] = encoder.fit_transform(data[column])\n",
    "        encoded[column] = {i:class_name for i, class_name in enumerate(encoder.classes_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a107686",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a548b1fc",
   "metadata": {},
   "source": [
    "### Analisis Korelasi Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ad51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data=data[:-1].corr(), annot=True, cmap=\"coolwarm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c316e0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(data=data, hue=\"diagnosis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac0eb3b",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[data.columns[:-1]]\n",
    "y = data[data.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb6f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff8c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7ae090",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70982321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(data_df, threshold):\n",
    "    corr_col = set()\n",
    "    corr_matrix = data_df.corr()\n",
    "    print (corr_matrix)\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range (i+1, len(corr_matrix.columns)):\n",
    "            if (np.abs(corr_matrix.iloc[(i, j)]) > threshold):\n",
    "                corr_col.add(corr_matrix.columns[j])\n",
    "    \n",
    "    return corr_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fedbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_col = correlation(x_train, 0.9)\n",
    "print (corr_col)\n",
    "print (len(corr_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(columns=corr_col, axis=1)\n",
    "x_test = x_test.drop(columns=corr_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e29135",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea2778",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_x_minmax = MinMaxScaler()\n",
    "scaler_x_standard = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b991c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scaling (x1, x2, scaler_x):\n",
    "    x1 = scaler_x.fit_transform(x1)\n",
    "    x2 = scaler_x.transform(x2)\n",
    "\n",
    "    return x1, x2, scaler_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e76a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, x_test_1, scaler_x_minmax = Scaling(x_train, x_test, scaler_x_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2, x_test_2, scaler_x_standard = Scaling(x_train, x_test, scaler_x_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593389a",
   "metadata": {},
   "source": [
    "### Prediction Scaling (MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4ca7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X=x_train_1, y=y_train)\n",
    "\n",
    "y_pred = model.predict(x_test_1)\n",
    "\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "rmse = root_mean_squared_error(y_pred, y_test)\n",
    "roc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "\n",
    "conf = confusion_matrix(y_pred, y_test)\n",
    "report = classification_report(y_pred, y_test)\n",
    "\n",
    "print (f\"MSE {mse}\")\n",
    "print (f\"RMSE {rmse}\")\n",
    "print (f\"ROC Score {roc}\")\n",
    "\n",
    "print (f\"Accuracy {accuracy}\")\n",
    "print (f\"Precision {precision}\")\n",
    "print (f\"Recall {recall}\")\n",
    "\n",
    "print (f\"Confusion Matrix {conf}\")\n",
    "print (f\"Classification Report {report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbde0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X=x_train_1, y=y_train)\n",
    "\n",
    "y_pred = model.predict(x_test_1)\n",
    "\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "rmse = root_mean_squared_error(y_pred, y_test)\n",
    "roc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_pred, y_test)\n",
    "\n",
    "print (f\"MSE {mse}\")\n",
    "print (f\"RMSE {rmse}\")\n",
    "print (f\"ROC Score {roc}\")\n",
    "\n",
    "print (f\"Accuracy {accuracy}\")\n",
    "print (f\"Precision {precision}\")\n",
    "print (f\"Recall {recall}\")\n",
    "\n",
    "print (f\"Confusion Matrix {conf}\")\n",
    "print (f\"Classification Report {report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a739d0e",
   "metadata": {},
   "source": [
    "### Prediction Scaling (Standard Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e56486",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X=x_train_2, y=y_train)\n",
    "\n",
    "y_pred = model.predict(x_test_2)\n",
    "\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "rmse = root_mean_squared_error(y_pred, y_test)\n",
    "roc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "\n",
    "conf = confusion_matrix(y_pred, y_test)\n",
    "report = classification_report(y_pred, y_test)\n",
    "\n",
    "print (f\"MSE {mse}\")\n",
    "print (f\"RMSE {rmse}\")\n",
    "print (f\"ROC Score {roc}\")\n",
    "\n",
    "print (f\"Accuracy {accuracy}\")\n",
    "print (f\"Precision {precision}\")\n",
    "print (f\"Recall {recall}\")\n",
    "\n",
    "print (f\"Confusion Matrix {conf}\")\n",
    "print (f\"Classification Report {report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de004761",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X=x_train_2, y=y_train)\n",
    "\n",
    "y_pred = model.predict(x_test_2)\n",
    "\n",
    "mse = mean_squared_error(y_pred, y_test)\n",
    "rmse = root_mean_squared_error(y_pred, y_test)\n",
    "roc = roc_auc_score(y_pred, y_test)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "precision = precision_score(y_pred, y_test)\n",
    "recall = recall_score(y_pred, y_test)\n",
    "\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_pred, y_test)\n",
    "\n",
    "print (f\"MSE {mse}\")\n",
    "print (f\"RMSE {rmse}\")\n",
    "print (f\"ROC Score {roc}\")\n",
    "\n",
    "print (f\"Accuracy {accuracy}\")\n",
    "print (f\"Precision {precision}\")\n",
    "print (f\"Recall {recall}\")\n",
    "\n",
    "print (f\"Confusion Matrix {conf}\")\n",
    "print (f\"Classification Report {report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998a8ca5",
   "metadata": {},
   "source": [
    "### Kesimpulan Classification\n",
    "\n",
    "Karena nilai Accuracy dari Logistic Regression > daripada Naive Bayes Model, maka kesimpulan yang bisa diperoleh adalah:\n",
    "\n",
    "1. Data features yang ada pada dataset tersebut bersifat dependent terhadap satu dengan yang lainnya, karena Naive Bayes menggunakan asumsi Naive, dimana asumsi tersebut seperti menyatakan bahwa setiap fitur bersifat independent, namun kenyataannya akurasi Logistic Regression lebih tinggi, sehingga bisa dibilang data-data pada dataset ini bersifat dependent terhadap satu dengan yang lainnya.\n",
    "\n",
    "2. Data tidak berdistribusi normal, penyebaran data tidak merata, karena Akurasi Logistic lebih tinggi\n",
    "\n",
    "3. Dataset sudah lumayan stabil dan tidak terlalu banyak noise, karena jika banyak noise seharusnya akurasi Naive Bayes lebih tinggi, karena Naive Bayes bisa tahan terhadap noise akibat asumsi Naive tersebut.\n",
    "\n",
    "4. Pemisahan kelas dan fitur bersifat linear, artinya lebih banyak data yang bersifat numeric dibandingkan categorical, karena Naive Bayes lebih cocok dalam Multi Classification, dimana terdapat cukup banyak kolom yang bersifat categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb098e",
   "metadata": {},
   "source": [
    "# Predicted Values vs  Actual Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740c5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Membandingkan Predicted Values dan Actual Values\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Scatter plot antara Predicted dan Actual\n",
    "plt.scatter(y_test, y_pred, color='blue', label='Data Points', alpha=0.6)\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, label=\"Ideal Line (y = x)\")  # Garis ideal\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Predicted Values vs Actual Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = np.sum(y_test != y_pred)\n",
    "print(f'Jumlah kesalahan prediksi: {errors} dari {len(y_test)} sampel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
